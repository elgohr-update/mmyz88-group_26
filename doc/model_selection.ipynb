{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "Authors: Yuanzhe Marco Ma, Arash Shamseddini, Kaicheng Tan, Zhenrui Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [General Overview](#1)\n",
    "- [Data preprocessing](#2)\n",
    "- [Ridge](#3)\n",
    "- [SVR](#4)\n",
    "- [Random Forest](#5)\n",
    "- [Conclusion](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. General Overview <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the IMDB scores (ranging from 0 ~ 10), we decided to choose the best model from three sklearn (Pedregosa et al. 2011) candiatates, sklearn linear_model Ridge, sklearn SVR(RBF kernel) estimator, and sklearn ensemble RandomForestRegressor. The score we would like to use is $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import (\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data preprocessing <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['n_words']\n",
    "text_feature = 'Text'\n",
    "ordinal_features = ['sentiment']\n",
    "drop_features = ['Id', 'Author']\n",
    "target = 'Rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Data/processed/train.csv\")\n",
    "X_train, y_train = train_df.drop(columns=[target] + drop_features), train_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', CountVectorizer(max_features=20_000, max_df=0.6), text_feature),\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('ord', OrdinalEncoder(categories=[['neg', 'compound', 'neu', 'pos']]), ordinal_features)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.Ridge <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   44.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('prepro',\n",
       "                                        ColumnTransformer(transformers=[('text',\n",
       "                                                                         CountVectorizer(max_df=0.6,\n",
       "                                                                                         max_features=20000),\n",
       "                                                                         'Text'),\n",
       "                                                                        ('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['n_words']),\n",
       "                                                                        ('ord',\n",
       "                                                                         OrdinalEncoder(categories=[['neg',\n",
       "                                                                                                     'compound',\n",
       "                                                                                                     'neu',\n",
       "                                                                                                     'pos']]),\n",
       "                                                                         ['sentiment'])])),\n",
       "                                       ('Ridge', Ridge())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'Ridge__alpha': array([ 800,  850,  900,  950, 1000, 1050, 1100, 1150])},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"prepro\", preprocessor),\n",
    "            (\"Ridge\", Ridge())\n",
    "        ]\n",
    "    )\n",
    "param_grid = {\n",
    "        'Ridge__alpha': np.arange(800, 1200, 50)\n",
    "    }\n",
    "hyper_parameters_search = GridSearchCV(ridge_pipe, param_grid=param_grid, n_jobs=-1, scoring='r2', verbose=1)\n",
    "hyper_parameters_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.198422</td>\n",
       "      <td>0.511951</td>\n",
       "      <td>0.53279</td>\n",
       "      <td>0.799778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fit_time  score_time  test_score  train_score\n",
       "Ridge  2.198422    0.511951     0.53279     0.799778"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = {}\n",
    "scores = cross_validate(\n",
    "    hyper_parameters_search.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='r2',\n",
    "    return_train_score=True)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "results_df[\"Ridge\"] = df.mean()\n",
    "pd.DataFrame(results_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tuned the Alpha hyperparameter of Ridge using sklearn's [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). The Alpha hyperparameter controls the complexity of our model. We want to pick the best Alpha so that our model does a decent job in predicting while avoiding over-fitting. Based on the tuning, we found that when alpha=800, we could get the best result. The result is shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.SVR <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed: 12.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('prepro',\n",
       "                                        ColumnTransformer(transformers=[('text',\n",
       "                                                                         CountVectorizer(max_df=0.6,\n",
       "                                                                                         max_features=20000),\n",
       "                                                                         'Text'),\n",
       "                                                                        ('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['n_words']),\n",
       "                                                                        ('ord',\n",
       "                                                                         OrdinalEncoder(categories=[['neg',\n",
       "                                                                                                     'compound',\n",
       "                                                                                                     'neu',\n",
       "                                                                                                     'pos']]),\n",
       "                                                                         ['sentiment'])])),\n",
       "                                       ('svr', SVR())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'svr__gamma': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008,\n",
       "       0.0009, 0.001 , 0.0011, 0.0012, 0.0013, 0.0014])},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"prepro\", preprocessor),\n",
    "            (\"svr\", SVR())\n",
    "        ]\n",
    "    )\n",
    "param_grid = {\n",
    "        'svr__gamma': np.arange(0.0001, 0.0015, 0.0001)\n",
    "    }\n",
    "hyper_parameters_search = GridSearchCV(svr_pipe, param_grid=param_grid, n_jobs=-1, scoring='r2', verbose=1)\n",
    "hyper_parameters_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.198422</td>\n",
       "      <td>0.511951</td>\n",
       "      <td>0.532790</td>\n",
       "      <td>0.799778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>28.988741</td>\n",
       "      <td>8.086322</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.723018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fit_time  score_time  test_score  train_score\n",
       "Ridge   2.198422    0.511951    0.532790     0.799778\n",
       "SVR    28.988741    8.086322    0.469965     0.723018"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    hyper_parameters_search.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='r2',\n",
    "    return_train_score=True)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "results_df[\"SVR\"] = df.mean()\n",
    "pd.DataFrame(results_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tuned our model with hyper-parameter optimization. Specifically, we tuned the Gamma hyperparameter of SVR using sklearn's GridSearchCV. The Gamma hyperparameter controls the complexity of our model. We want to pick the best Gamma so that our model does a decent job in predicting while avoiding over-fitting.\n",
    "\n",
    "Below is our tuned, best performing model based on cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model Name | Hyperparameter - Gamma | Mean Fit Time |  Mean Scoring Time | Mean CV Score |\n",
    "|------------|------------------------|---------------|--------------------|---------------|\n",
    "|    SVR     |  0.0007000000000000001 | 43.80s | 11.40s |0.4700 |\n",
    "\n",
    "For a more detailed GridSearchCV result, see [this file](../results/hyper_param_search_result.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Random Forest <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuzhe\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 9 is smaller than n_iter=1000. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('prepro',\n",
       "                                              ColumnTransformer(transformers=[('text',\n",
       "                                                                               CountVectorizer(max_df=0.6,\n",
       "                                                                                               max_features=20000),\n",
       "                                                                               'Text'),\n",
       "                                                                              ('num',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['n_words']),\n",
       "                                                                              ('ord',\n",
       "                                                                               OrdinalEncoder(categories=[['neg',\n",
       "                                                                                                           'compound',\n",
       "                                                                                                           'neu',\n",
       "                                                                                                           'pos']]),\n",
       "                                                                               ['sentiment'])])),\n",
       "                                             ('randomforestregressor',\n",
       "                                              RandomForestRegressor(random_state=26))]),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'randomforestregressor__max_depth': [20,\n",
       "                                                                             25,\n",
       "                                                                             30],\n",
       "                                        'randomforestregressor__n_estimators': [1,\n",
       "                                                                                10,\n",
       "                                                                                100]},\n",
       "                   scoring='r2')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"prepro\", preprocessor),\n",
    "            (\"randomforestregressor\", RandomForestRegressor(random_state=26))\n",
    "        ]\n",
    " )\n",
    "param_grid1 = {\n",
    "        'randomforestregressor__max_depth': [int(x) for x in np.linspace(20, 30, num = 3)],\n",
    "        'randomforestregressor__n_estimators': [1, 10, 100]\n",
    "    }\n",
    "hyper_parameters_search = RandomizedSearchCV(rf_pipe, param_distributions=param_grid1, n_jobs=-1, scoring='r2', n_iter=1000)\n",
    "hyper_parameters_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__n_estimators': 100,\n",
       " 'randomforestregressor__max_depth': 30}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_parameters_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.198422</td>\n",
       "      <td>0.511951</td>\n",
       "      <td>0.532790</td>\n",
       "      <td>0.799778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>28.988741</td>\n",
       "      <td>8.086322</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.723018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>287.661862</td>\n",
       "      <td>0.499031</td>\n",
       "      <td>0.359660</td>\n",
       "      <td>0.906179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fit_time  score_time  test_score  train_score\n",
       "Ridge                    2.198422    0.511951    0.532790     0.799778\n",
       "SVR                     28.988741    8.086322    0.469965     0.723018\n",
       "RandomForestRegressor  287.661862    0.499031    0.359660     0.906179"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    hyper_parameters_search.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='r2',\n",
    "    return_train_score=True)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "results_df[\"RandomForestRegressor\"] = df.mean()\n",
    "pd.DataFrame(results_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is our aim to compare the performance of our SVR with two other models: RandomForesetRegressor and Ridge, in terms of validation R2 scores. For RandomForestRegressor, we tuned two major hyperparameters of the regressor, namely, max_depth and n_estimators simultaneously. The results of hyperparameter optimization indicate that increasing both max_depth and n_estimators of the model improves the performance of the model over the training set continuously, however the validation scores are not improved significantly (changes in the order of  10âˆ’4 ). According to above results, the model is overfitting with our data as the gap between the train and test scores is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Conclusion <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, Random Forest is not a suitable model for our project. Based on our tuning result, the validation scores of Ridge and SVR are pretty close. Althouogh the validation score of Ridge is slightly higher compared with that of SVR, the gap between the validation score and training score is also higher in Ridge. Cinsidering the generalizations, we decided to use SVR(RBF kernel)  as our model to do the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011. (https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html) <a class=\"anchor\" id=\"c3\"></a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
